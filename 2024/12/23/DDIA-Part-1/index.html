<!DOCTYPE html>
<html>
    <head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover" name="viewport" />
    <meta name="robots" content="index, follow">

    <!-- Baidu Site SEO -->
    <meta name="baidu-site-verification" content="codeva-Fn6WoXLOMw" />
    <!-- <meta name="baidu-site-verification" content="codeva-mdLm33TTHY" /> -->

    <!-- Baidu analytics -->
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?1a364896f028f8093396007dc78eb0a0";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-WF4EY3839B"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-WF4EY3839B');
    </script>

    <!-- Bing Site SEO -->
    <meta name="msvalidate.01" content="85648BC2E966622B7CC9FF6BCB04E326" />

    <!-- title -->
    
        <title>Designing Data-Intensive Applications - Part I Foundations of Data Systems | Lili Liang</title>
    
  
    <!-- Open graph -->
    <meta name="description" content="CHAPTER 1 Reliable, Scalable, and Maintainable Applications  Thinking About Data Systems Reliability  Human Errors   Scalability  Describing Load Approaches for Coping with Load   Maintainability">
<meta property="og:type" content="article">
<meta property="og:title" content="Designing Data-Intensive Applications - Part I Foundations of Data Systems">
<meta property="og:url" content="https://leungll.site/2024/12/23/DDIA-Part-1/index.html">
<meta property="og:site_name" content="Lili Liang">
<meta property="og:description" content="CHAPTER 1 Reliable, Scalable, and Maintainable Applications  Thinking About Data Systems Reliability  Human Errors   Scalability  Describing Load Approaches for Coping with Load   Maintainability">
<meta property="og:locale">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/leungll/MyImgHosting/img/DDIA-Part1-C1-01.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/leungll/MyImgHosting/img/DDIA-Part1-C1-02.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/leungll/MyImgHosting/img/DDIA-Part1-C1-03.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/leungll/MyImgHosting/img/DDIA-Part1-C1-04.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/leungll/MyImgHosting/img/DDIA-Part1-C2-01.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/leungll/MyImgHosting/img/DDIA-Part1-C3-01.png">
<meta property="article:published_time" content="2024-12-23T16:11:42.000Z">
<meta property="article:modified_time" content="2025-04-07T00:58:23.873Z">
<meta property="article:author" content="Lili Liang 梁莉莉">
<meta property="article:tag" content="System Design">
<meta property="article:tag" content="Distributed System">
<meta property="article:tag" content="Data System">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/leungll/MyImgHosting/img/DDIA-Part1-C1-01.png">

    <!-- Canonical -->
    
        <link rel="canonical" href="https://leungll.site/2024/12/23/DDIA-Part-1/">
    

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/logo.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/img/logo.png">

    <!-- CSS -->
    
<link rel="stylesheet" href="/css/reset.css">

    
<link rel="stylesheet" href="/css/style.css">

    
<link rel="stylesheet" href="/css/markdown.css">

    
<link rel="stylesheet" href="/css/fonts.css">


    <script>
        MathJax = {
          tex: {
            packages: ['base', 'ams'],
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            processEscapes: true
          },
          options: {
            ignoreHtmlClass: "tex2jax_ignore",
            processHtmlClass: "tex2jax_process"
          }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Lili Liang" type="application/atom+xml">
</head>

    <body>
        <div class="paper">
            <div class="paper-main">
                
                    <div class="post-header">
    <a class="logo" href="/">Lili Liang 梁莉莉</a>
    <!-- <div class="logo"><a href="/" title="Len"><img src="/img/logo.svg" alt="Len" aria-label="logo" height="20"></a></div> -->
        <ul class="nav">
            
            <li><a href="/">Blogs</a></li>
            
            <li><a href="/archives">Archives</a></li>
            
            <li><a href="/about">About</a></li>
            
        </ul>
    </a>
</div>

                
                <div class="post-main">
    
        <!-- Post Title -->
        <div class="post-main-title">
            Designing Data-Intensive Applications - Part I Foundations of Data Systems
        </div>

        <!-- Post Meta Information -->
        <div class="post-meta">
            <!-- Show Creation Date -->
            Created: Dec 24, 2024 ｜ 

            <!-- Show Last Updated Date -->
            
                Last updated: Apr 7, 2025 ｜ 
            

            <!-- Show Post Categories -->
            
                <a href="/categories/System-Design/"># System Design</a>
            
        </div>

        <!-- Post Content -->
        <div class="post-md">
            <!-- toc -->
<ul>
<li><a href="#chapter-1-reliable-scalable-and-maintainable-applications">CHAPTER 1 Reliable, Scalable, and Maintainable Applications</a>
<ul>
<li><a href="#thinking-about-data-systems">Thinking About Data Systems</a></li>
<li><a href="#reliability">Reliability</a>
<ul>
<li><a href="#human-errors">Human Errors</a></li>
</ul>
</li>
<li><a href="#scalability">Scalability</a>
<ul>
<li><a href="#describing-load">Describing Load</a></li>
<li><a href="#approaches-for-coping-with-load">Approaches for Coping with Load</a></li>
</ul>
</li>
<li><a href="#maintainability">Maintainability</a></li>
</ul>
</li>
<li><a href="#chapter-2-data-models-and-query-languages">CHAPTER 2 Data Models and Query Languages</a>
<ul>
<li><a href="#relational-model-versus-document-model">Relational Model Versus Document Model</a></li>
<li><a href="#query-languages-for-data">Query Languages for Data</a>
<ul>
<li><a href="#declarative-queries-on-web">Declarative Queries on Web</a></li>
<li><a href="#mapreduce-querying">MapReduce Querying</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#chapter-3-storage-and-retrieval">CHAPTER 3 Storage and Retrieval</a>
<ul>
<li><a href="#data-structures-that-power-your-database">Data Structures That Power Your Database</a>
<ul>
<li><a href="#hash-indexes">Hash Indexes</a></li>
<li><a href="#sstables-and-lsm-trees">SSTables and LSM-Trees</a></li>
<li><a href="#b-trees">B-Trees</a></li>
<li><a href="#comparing-b-trees-and-lsm-trees">Comparing B-Trees and LSM-Trees</a></li>
</ul>
</li>
<li><a href="#transaction-processing-or-analytics">Transaction Processing or Analytics?</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<h1><span id="chapter-1-reliable-scalable-and-maintainable-applications">CHAPTER 1 Reliable, Scalable, and Maintainable Applications</span></h1>
<h2><span id="thinking-about-data-systems">Thinking About Data Systems</span></h2>
<p>One possible architecture for a data system that combines several components.</p>
<p><img src="https://cdn.jsdelivr.net/gh/leungll/MyImgHosting/img/DDIA-Part1-C1-01.png" alt="DDIA-Part1-C1-01"></p>
<p>Three concerns that are important in most software systems:</p>
<p><strong>Reliability</strong></p>
<ul>
<li>The system should continue to <strong>work correctly</strong> (performing the correct function at the desired level of performance) even in the face of adversity (hardware or software faults, and even human error).</li>
</ul>
<p><strong>Scalability</strong></p>
<ul>
<li>As the system grows (in data volume, traffic volume, or complexity), there should <strong>be reasonable ways of dealing with that growth</strong>.</li>
</ul>
<p><strong>Maintainbility</strong></p>
<ul>
<li>Over time, many different people will work on the system (engineering and operations, both maintaining current behavior and adapting the system to new use cases), and they should all be able to <strong>work on it productively</strong>.</li>
</ul>
<h2><span id="reliability">Reliability</span></h2>
<h3><span id="human-errors">Human Errors</span></h3>
<blockquote>
<p>One study of large internet services found that <strong>configuration errors by operators were the leading cause of outages</strong>, whereas hardware faults (servers or network) played a role in only 10–25% of outages.</p>
</blockquote>
<p>How do we make our systems reliable, in spite of unreliable humans?</p>
<ul>
<li><strong>Design systems</strong> in a way that <strong>minimizes opportunities for error</strong>. For example, well-designed abstractions, APIs, and admin interfaces.</li>
<li><strong>Decouple the places</strong> where people make the most mistakes from the places where they can cause failures. In particular, <strong>provide fully featured non-production sandbox environments</strong> where people can explore and experiment safely, using real data, without affecting real users.</li>
<li><strong>Test thoroughly</strong> at all levels, from unit tests to whole-system integration tests and manual tests. Automated testing is widely used.</li>
<li>Allow <strong>quick and easy recovery</strong> from human errors, to <strong>minimize the impact in the case of a failure</strong>. For example, <strong>make it fast to roll back configuration changes</strong>, <strong>roll out new code gradually</strong> (so that any unexpected bugs affect only a small subset of users), and provide tools to recompute data.</li>
<li>Set up <strong>detailed and clear monitoring</strong>, such as performance metrics and error rates.</li>
<li>Implement good management practices and training—a complex and important aspect.</li>
</ul>
<h2><span id="scalability">Scalability</span></h2>
<h3><span id="describing-load">Describing Load</span></h3>
<p>Let’s consider Twitter as an example.</p>
<p>Twitter’s scaling challenge is not primarily due to tweet volume, but due to <strong>fan-out</strong> - each user follows many people, and each user is followed by many people. There are broadly two ways of implementing these two operations:</p>
<ol>
<li>
<p>Posting a tweet simply <strong>inserts the new tweet</strong> into a global collection of tweets. When a user requests their home timeline, <strong>look up all the people they follow</strong>, find all the tweets for each of those users, and <strong>merge them (sorted by time)</strong>.</p>
<p><img src="https://cdn.jsdelivr.net/gh/leungll/MyImgHosting/img/DDIA-Part1-C1-02.png" alt="DDIA-Part1-C1-02"></p>
<p><img src="https://cdn.jsdelivr.net/gh/leungll/MyImgHosting/img/DDIA-Part1-C1-03.png" alt="DDIA-Part1-C1-03"></p>
</li>
<li>
<p><strong>Maintain a cache for each user’s home timeline</strong>—like a mailbox of tweets for each recipient user. When a user posts a tweet, <strong>look up all the people who follow that user, and insert the new tweet into each of their home timeline caches</strong>. The request to read the home timeline is then cheap, because its result has been computed ahead of time.</p>
<p><img src="https://cdn.jsdelivr.net/gh/leungll/MyImgHosting/img/DDIA-Part1-C1-04.png" alt="DDIA-Part1-C1-04"></p>
</li>
</ol>
<p>The first version of Twitter used approach 1, but the systems struggled to keep up with the load of home timeline queries, so the company switched to approach 2. This works better because <strong>the average rate of published tweets is almost two orders of magnitude lower than the rate of home timeline reads</strong>, and so in this case it’s preferable to do more work at write time and less at read time.</p>
<p>In the example of Twitter, <strong>the distribution of followers per user (maybe weighted by how often those users tweet) is a key load parameter for discussing scalability</strong>, since it determines the fan-out load.</p>
<p>The final twist of the Twitter anecdote: now that approach 2 is robustly implemented, <strong>Twitter is moving to a hybrid of both approaches</strong>. <strong>Most users’ tweets continue to be fanned out to home timelines</strong> at the time when they are posted, but a small number of users with a very large number of followers (i.e., celebrities) are excepted from this fan-out. <strong>Tweets from any celebrities that a user may follow are fetched separately and merged with that user’s home timeline when it is read, like in approach 1</strong>.</p>
<h3><span id="approaches-for-coping-with-load">Approaches for Coping with Load</span></h3>
<p>People often talk of a dichotomy between <strong>scaling up</strong> (vertical scaling, moving to a more powerful machine) and <strong>scaling out</strong> (horizontal scaling, distributing the load across multiple smaller machines).</p>
<h2><span id="maintainability">Maintainability</span></h2>
<p>We will pay attention to three design principles for software systems:</p>
<ul>
<li>
<p>Operability</p>
<ul>
<li>Make it easy for <strong>operations teams</strong> to <strong>keep the system running smoothly</strong>.</li>
</ul>
</li>
<li>
<p>Simplicity</p>
<ul>
<li>Make it easy for <strong>new engineers</strong> to <strong>understand the system</strong>, by removing as much complexity as possible from the system.</li>
</ul>
</li>
<li>
<p>Evolvability</p>
<ul>
<li>Make it easy for <strong>engineers</strong> to <strong>make changes</strong> to the system in the future.</li>
</ul>
</li>
</ul>
<h1><span id="chapter-2-data-models-and-query-languages">CHAPTER 2 Data Models and Query Languages</span></h1>
<h2><span id="relational-model-versus-document-model">Relational Model Versus Document Model</span></h2>
<p>Document Model: The main arguments in favor of the document data model are <strong>schema flexibility</strong>, <strong>better performance due to locality</strong>, and that for some applications it is closer to the data structures used by the application.<br>
Relational model: The relational model counters by providing <strong>better support for joins, and many-to-one and many-to-many relationships</strong>.</p>
<h2><span id="query-languages-for-data">Query Languages for Data</span></h2>
<p><strong>Declarative languages</strong>, like SQL, have a better chance of getting faster in parallel execution because they <strong>specify only the pattern of the results</strong>, not the algorithm that is used to determine the resules.</p>
<p><strong>Imperaive code</strong> is very hard to parallelize across multiple cores and multiple machines, because it <strong>specifies instructions that must be performed in a particular code</strong>.</p>
<h3><span id="declarative-queries-on-web">Declarative Queries on Web</span></h3>
<p>In a web browser, <strong>using declarative CSS styling</strong> is much better than manipulating styles imperatively in JavaScript. Similarly, in databases, <strong>declarative query languages like SQL turned out to be much better than imperative query APIs</strong>.</p>
<h3><span id="mapreduce-querying">MapReduce Querying</span></h3>
<p>MapReduce is a <strong>programming model</strong> for <strong>processing large amounts of data in bulk across many machines</strong>, popularized by Google. A limited form of MapReduce is supported by some NoSQL datastores, including MongoDB and CouchDB, as a mechanism for performing read-only queries across many documents.</p>
<p>MapReduce is neither a declarative query language nor a fully imperative query API, but somewhere in between: the logic of the query is expressed with snippets of code, which are called repeatedly by the processing framework. <strong>It is based on the map (also known as <u>collect</u>) and reduce (also known as <u>fold or inject</u>) functions</strong> that exist in many functional programming languages.</p>
<p><img src="https://cdn.jsdelivr.net/gh/leungll/MyImgHosting/img/DDIA-Part1-C2-01.png" alt="DDIA-Part1-C2-01"></p>
<p>The <code>map</code> function would be called once for each document, resulting in emit(“1995-12”, 3) and emit (“1995-12”, 4). Subsequently, the reduce function would be called with reduce(“1995-12”, [3, 4]), returning 7.</p>
<p>MapReduce is a fairly <u>low-level programming model</u> for <u>distributed execution</u> on a cluster of machines. Higher-level query languages like SQL can be implemented as a pipeline of MapReduce operations.</p>
<p>A declarative query language offers more opportunities for a query optimizer to improve the performance of a query.</p>
<h1><span id="chapter-3-storage-and-retrieval">CHAPTER 3 Storage and Retrieval</span></h1>
<h2><span id="data-structures-that-power-your-database">Data Structures That Power Your Database</span></h2>
<h3><span id="hash-indexes">Hash Indexes</span></h3>
<p>A storage engine like <strong>Bitcask</strong> is well suited to situations where the value for each key is updated frequently.</p>
<p>Lots of detail goes into making this simple idea work in practice. Briefly, some of the issues that are important in a real implementations are:</p>
<p><strong>File format</strong></p>
<ul>
<li>CSV is not the best format for a log. It’s faster and simpler to use a <strong>binary format</strong> that first encodes the length of a string in bytes, followed by the raw string (without need for escaping).</li>
</ul>
<p><strong>Deleting records</strong></p>
<ul>
<li>If you want to delete a key and its associated, you have to <u>append a special deletion record to the data file</u> (sometimes called a <strong>tombstone</strong>). When log segments are merged, the tombstone tells the merging process to discard any previous values for the deleted key.</li>
</ul>
<p><strong>Crash recovery</strong></p>
<ul>
<li>Bitcask speeds up recovery by <u>storing a snapshot of each elements’s hash map on disk</u>, which can be loaded into memory more quickly.</li>
</ul>
<p><strong>Partially written records</strong></p>
<ul>
<li>The database may crash at any time, including halfway through appending a record to the log. Bitcask files include <strong>checksums</strong>, allowing such corrupted parts of the log to be detected and ignored.</li>
</ul>
<p><strong>Concurrenncy control</strong></p>
<ul>
<li>As writes are <u>appended to the log in a strictly sequential order</u>, a common implementation choice is to <u>have only one writer thread</u>. Data file segments are <strong>append-only</strong> and <strong>otherwise immutable</strong>, so they can be read concurrently by multiple threads.</li>
</ul>
<p>An append-only logs seems wasteful at first glance: why don’t you update the file in place, overwriting the old value with the new value? <strong>But an append-only design turns out to be good for several reasons</strong>:</p>
<ul>
<li>
<p><u>Appending and segment merging are sequential write operations</u>, which are generally much faster than random writes, expecially on magnetic spinning-disk hard drives.</p>
</li>
<li>
<p><u>Concurrenct and crash recovery are much simpler</u> if segment files are append-only or immutable. For example, you don’t have to worry about the case where a crash happened while a value was being overwritten, leaving you with a file containing part of the old and part of the new value spliced together.</p>
</li>
<li>
<p>Merging old segments <u>avoids the problem of data files getting fragmented</u> over time.</p>
</li>
</ul>
<p>However, <strong>the hash table index also has limitations</strong>:</p>
<ul>
<li>
<p><u>The hash table must fit in memory</u>. It is difficult to make an on-dish hash map perform well. It requires a lot of random access I/O, it is expensive to grow when it becomes full, and hash collisions require fiddly logic.</p>
</li>
<li>
<p><u>Range queries are not efficient</u>. For example, you cannot easily scan over all keys between kitty00000 and kitty99999 - you have to look up each key individually in the hash maps.</p>
</li>
</ul>
<h3><span id="sstables-and-lsm-trees">SSTables and LSM-Trees</span></h3>
<p>SSTable: Sorted String Table</p>
<p><strong>Constructing and maintaining SSTables</strong><br>
We can now make our storage engine work as follows:</p>
<ul>
<li>
<p>When a write comes in, <u>add it to an in-memory balanced tree</u> data structure (for example, a red-black tree). This in-memory tree is sometimes called a memtable.</p>
</li>
<li>
<p>When the memtable gets bigger than some threshold, <u>write it out to disk as an SSTable file</u>. This can be done efficiently because the tree already maintains the key-value pairs sorted by key. The new SSTable file becomes the most recend segment of the database. While the SSTable is being written out to disk, writes can continue to a new memtable instance.</p>
</li>
<li>
<p>In order to serve a read request, first try to <u>find the key in the memtable</u>, then <u>in the most recent segment of the database</u>, then <u>in the next-older segment</u>, etc.</p>
</li>
<li>
<p>From time to time, <u>run a merging and compaction process in the background</u> to combine segment files and to discard overwritten or deleted values.</p>
</li>
</ul>
<p>This scheme works very well. <strong>It only suffers from one problem</strong>: if the databse crashed, the most recent writes (which are in the memtable but not yet written out to disk) are lost.</p>
<p><strong>In order to avoid that problem</strong>, we can <u>keep a separate log on disk to which every write is immediately appended</u>. Every time the memtable is written out to an SSTable, the corresponding log can be discarded.</p>
<p><strong>Making an LSM-tree out of SSTables</strong><br>
LSM-tree: Log-Structured Merge-Tree</p>
<p>Storage engines that are based on this principle of <u>merging and compacting sorted files</u> are often called <strong>LSM storage engines</strong>.</p>
<p><strong>Lucene</strong>, an indexing engine for full-text search used by Elasticsearch and Solr, uses a similar method for storing its term dictionary. A full-text index is much more complex than a key-value index <u>but is based on a similar idea: given a word in a search query, find all the documents (web pages, product descriptions, etc.) that mention the word.</u> This is implemented with a key-value structure where the <u>key is a word (a term)</u> and the <u>value is the list of IDs of all the documents that contain the word (the postings list).</u> In Lucene, this mapping from term to postings list is <u>kept in SSTable-like sorted files</u>, which are merged in the background as needed.</p>
<p><strong>Performance optimizations</strong><br>
The LSM-tree algorithm can be slow when looking up keys that <u>do not exist in the database</u>: you have to check the <u>memtable</u>, then the <u>segments all the way back to the oldest</u> (possibly having to <u>read from disk</u> for each one) before you can be sure that the key does not exist. In order ro optimize this kind of access, storage engines often use additional <strong>Bloom filters</strong>. (A Bloom filter is a <strong>memory-efficient data structure</strong> for approximating the contents of a set. It can <u>tell you if a key does not appear in the database</u>, and thus saves many unnecessary disk reads for nonexistent keys.)</p>
<h3><span id="b-trees">B-Trees</span></h3>
<p>Like SSTable, B-trees keep key-value pairs sorted by key, which allows efficient key-value lookups and range queries. But that’s where the similarity ends: B-trees have a very different design philosophy.</p>
<p>The <strong>log-structured indexes</strong> we saw earlier <u>break the database down into variable-size segments</u>, typically several megabytes or more in size, and always <u>write a segment sequentially</u>. By contrast, <strong>B-trees</strong> <u>break the database down into fixed-size blocks or pages</u>, traditionally 4 KB in size (sometimes bigger), and read or write one page at a time.</p>
<p><img src="https://cdn.jsdelivr.net/gh/leungll/MyImgHosting/img/DDIA-Part1-C3-01.png" alt="DDIA-Part1-C3-01"></p>
<p>One page is designated as the root of the B-tree; whenever you want to look up a key in the index, you start here. <u>The page contains several keys and references to child pages</u>. Each child is responsible <u>for a continuous range of keys</u>, and the <u>keys between the references indicate where the boundaries between those ranges lie</u>.</p>
<p><strong>Making B-trees reliable</strong><br>
The basic underlying <strong>write operation</strong> of a B-tree is to <strong>overwrite a page on disk with new data</strong>. Moreover, some operations require several different pages to be overwritten. This is a dangerous operation, because if the database crashed after only some of the pages have been written, you end up with a corrupted index.</p>
<p>In order to make the database resilient to crashes, it is common for B-tree implementations to include an additional data structure on disk: <strong>a write-ahead log (WAL, also known as a redo log)</strong>. This is <strong>an append-only file</strong> to which every B-tree modification must be written <u>before it can be applied to the pages of the tree itself</u>.</p>
<p>An additional complication of updating pages in place is that careful concurrency control is required if multiple threads are going to access the B-tree at the same time - otherwise a thread may see the tree in an inconsistent state. This is typically done by <strong>protecting the tree’s data structure with latches (lightweight locks)</strong>.</p>
<h3><span id="comparing-b-trees-and-lsm-trees">Comparing B-Trees and LSM-Trees</span></h3>
<p><strong>LSM-trees</strong> are typically faster for <strong>writes</strong>, whereas <strong>B-trees</strong> are thought to be faster for <strong>reads</strong>. Reads are typically slower on <strong>LSM-trees</strong> because they have to <u>check several different data structures and SSTables at different stages of compaction</u>.</p>
<p><strong>Advantages of LSM-trees</strong><br>
A <strong>B-tree index</strong> must write every piece of data <strong>at least twice</strong>: once to the <u>write-ahead log</u>, and once to <u>the tree page itself</u> (and perhaps again as pages are split). There is also overhead from having to write an entire page at a time, even if only a few bytes in that page changed. Some storage engines even overwrite the same page twice in order to avoid ending up with a partially updated page in the event of a power failure.</p>
<p><strong>Log-structured indexes</strong> also <strong>rewrite data multiple times</strong> due to <u>repeated compaction and merging of SSTable</u>. This effect is known as <strong>write amplification</strong>.</p>
<p>Moreover, <u><strong>LSM-trees</strong> are typically able to <strong>sustain higher write throughput</strong> than B-trees</u>, partly because they sometimes <u>have lower write amplification</u>, and partly because they <u>sequentially write compact SSTable files rather than having to overwrite several pages in the tree</u>. This difference is particularly important on magnetic hard drives, where <u>sequential writes are much faster than random writes</u>.</p>
<p><strong>LSM-trees</strong> can be compressed better, and thus often <u>produce smaller files</u> on disk than B-trees. Since LSM-trees <u>are not page-oriented and periodically rewrite SSTable</u> to remove fragmentation, they have lower storage overheads.</p>
<p><strong>Downsides of LSM-trees</strong><br>
A <strong>downside of log-structured storage</strong> is that the <u>&gt;compaction process can sometims interfere with the performance of ongoing reads and writes</u>.</p>
<p>An <strong>advantage of B-trees</strong> is that <u>each key exists in exactly one place in the index</u>, whereas a log-structured storage engine may have multiple copies of the same key in different segments. This aspect <u>makes B-trees attractive in database that want to offer strong transactional semantics</u>: in many relational databases, transaction isolation is implemented using locks on range of keys, and <u>in a B-tree index, those locks can be directly attached to the tree</u>.</p>
<h2><span id="transaction-processing-or-analytics">Transaction Processing or Analytics?</span></h2>

        </div>
    

    <!-- Post Tags -->
    
        <div class="post-meta">
            Tags:
            
                <a href="/tags/System-Design/"> / System Design</a>
            
                <a href="/tags/Distributed-System/"> / Distributed System</a>
            
                <a href="/tags/Data-System/"> / Data System</a>
            
        </div>
    
</div>
                <div class="footer">
    <span>Copyright © 2025 Lili Liang</span>
    <span>Build with <a target="_blank" rel="noopener" href="https://github.com/LenChou95/hexo-theme-ZenMind">ZenMind</a></span>
</div>

<!-- Copy Code Funciton -->
<script>
    document.addEventListener('DOMContentLoaded', (event) => {
        document.querySelectorAll('pre').forEach((pre) => {
            const button = document.createElement('button');
            button.innerText = 'Copy';
            button.className = 'copy-button';

            button.addEventListener('click', () => {
            const codeLines = pre.querySelectorAll('.hljs-ln-code');
            const codeContent = Array.from(codeLines)
                .map(line => line.textContent)
                .join('\n');

            navigator.clipboard.writeText(codeContent).then(() => {
                button.innerText = '√ Copied!';
                setTimeout(() => {
                button.innerText = 'Copy';
                }, 3000);
            }).catch(err => {
                console.error('Copy failed: ', err);
                alert('Unable to copy code, please check browser permissions!');
            });
            });

            pre.appendChild(button);
        });
    });
</script>

<!-- Change Code Style -->

<link rel="stylesheet" href="/css/a11y-dark.min.css">

<!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/github-dark.min.css"> -->


<script src="/js/highlight.min.js"></script>


<script src="/js/highlightjs-line-numbers.js"></script>


<script>
    hljs.initHighlightingOnLoad();
    hljs.initLineNumbersOnLoad();
</script>

            </div>
        </div>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>
</html>